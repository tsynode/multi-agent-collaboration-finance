{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8d63a2-913e-498a-a01a-5e66a39bf3e7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 3. Peak Load Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63678eaa-8830-4cbe-94af-5ebd8b0e03e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we show you how to create your third and last sub-agent on Amazon Bedrock Agents.\n",
    "\n",
    "This agent identifies non-essential processes that can be shifted to off-peak hours and redistributes the grid allocation.\n",
    "\n",
    "This agent can also provide energy saving tips based on the search of videos embedded in Bedrock Knowledge Bases.  \n",
    "\n",
    "The following represents the piece of architecture that will be built on this module.\n",
    "\n",
    "![Architecture](img/peak_laod_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba49fa-3293-4ea6-8dee-fb9f410c6481",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Make sure that your boto3 version is the latest one.\n",
    "\n",
    "If not, return no [notebook 1](../1-energy-forecast/1_forecasting_agent.ipynb) and run Setup block again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef0a80",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip freeze | grep boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf37dd5-bfaf-4563-a6ad-f9d7637c6e43",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating Agent\n",
    "\n",
    "On this section we declare global variables that will be act as helpers during entire notebook and we will start to create out second agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a742a-5f17-4dfc-ac36-1b70ce8f4f7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "import json, uuid\n",
    "import random\n",
    "sts_client = boto3.client('sts')\n",
    "#session = boto3.session.Session()\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket_name = session.default_bucket()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "#region = session.region_name\n",
    "region = 'us-west-2'\n",
    "account_id_suffix = account_id[:3]\n",
    "#agent_suffix = f\"{region}-{account_id_suffix}\"\n",
    "agent_suffix = random.randrange(200, 900)\n",
    "agent_foundation_model = [\n",
    "    'anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
    "    'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cc6c8-4faa-4adc-90c8-7ace112877e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peak_agent_name = f\"peak-agent-{agent_suffix}\"\n",
    "\n",
    "peak_lambda_name = f\"fn-peak-agent-{agent_suffix}\"\n",
    "\n",
    "peak_agent_role_name = f'AmazonBedrockExecutionRoleForAgents_{peak_agent_name}'\n",
    "\n",
    "dynamodb_table = f\"{peak_agent_name}-table\"\n",
    "dynamodb_pk = \"customer_id\"\n",
    "dynamodb_sk = \"item_id\"\n",
    "\n",
    "dynamoDB_args = [dynamodb_table, dynamodb_pk, dynamodb_sk]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c017998",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Importing helper functions\n",
    "\n",
    "On following section, we're adding `bedrock_agent_helper.py` on Python path, so the files can be recognized and their functionalities can be invoked.\n",
    "\n",
    "Now, you're going to import from helper classes `bedrock_agent_helper.py`.\n",
    " \n",
    "Those files contain helper classes totally focused on make labs experience smoothly. \n",
    "\n",
    "All interactions with Bedrock will be handled by these classes.\n",
    "\n",
    "Following are methods that you're going to invoke on this lab:\n",
    "\n",
    "On `agents.py`:\n",
    "- `create_agent`: Create a new agent and respective IAM roles\n",
    "- `add_action_group_with_lambda`: Create a lambda function and add it as an action group for a previous created agent\n",
    "- `create_agent_alias`: Create an alias for this agent\n",
    "- `invoke`: Execute agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785239e3-519e-4b39-a417-9b9ca3ce16ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \".\")\n",
    "sys.path.insert(1, \"..\")\n",
    "\n",
    "from utils.bedrock_agent_helper import (\n",
    "    AgentsForAmazonBedrock\n",
    ")\n",
    "agents = AgentsForAmazonBedrock()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fbbb35",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating Agent\n",
    "Create the Peak Load Manager agent that will have an action group to handle resource allocation and non-essential processes detection.\n",
    "\n",
    "For this agent we will use the following instructions:\n",
    "```\n",
    "You are a Peak Load Manager Bot that optimizes energy consumption patterns by analyzing IoT device data and process schedules.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Retrieving data from IoT devices\n",
    "2. Identifying non-essential loads during peak hours and reallocating them to other schedules\n",
    "3. Recommending schedule adjustments\n",
    "\n",
    "Response style:\n",
    "- Be precise and analytical\n",
    "- Use clear, practical language\n",
    "- Focus on actionable recommendations\n",
    "- Support suggestions with data\n",
    "- Be concise yet thorough\n",
    "- Do not request information that can be retrieved from IoT devices\n",
    "```\n",
    "\n",
    "And we will make the following tool available to the agent:\n",
    "- `detect_peak`: detect consumption peak during current month\n",
    "- `detect_non_essential_processes`: detect non-essential processes that are causing the peaks\n",
    "- `redistribute_allocation`: reduce/increase allocated quota for a specific item during current month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e168c8-180f-4977-96dd-d8006436208b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peak_agent = agents.create_agent(\n",
    "    peak_agent_name,\n",
    "    \"\"\"You are a peak load manager bot. \n",
    "    You can retrieve information from IoT devices and Knowledge Bases, \n",
    "    identify process and their peak energy consumption and suggest shifts to off-peak hours.\n",
    "    \"\"\",\n",
    "    \"\"\"You are a Peak Load Manager Bot that optimizes energy consumption patterns\n",
    "by analyzing IoT device data, video information from Knowledge Bases and process schedules.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Retrieving data from IoT devices and Knowledge Bases\n",
    "2. Identifying non-essential loads during peak hours and reallocating them to other schedules\n",
    "3. Recommending schedule adjustments\n",
    "4. Identify energy waste patterns inside residential areas and recommend energy saving tips\n",
    "\n",
    "Response style:\n",
    "- Be precise and analytical\n",
    "- Use clear, practical language\n",
    "- Focus on actionable recommendations\n",
    "- Support suggestions with data\n",
    "- Be concise yet thorough\n",
    "- Do not request information that can be retrieved from IoT devices\n",
    "    \"\"\",\n",
    "    agent_foundation_model\n",
    ")\n",
    "\n",
    "peak_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ddea6-dcca-49d0-8d51-57a49293507d",
   "metadata": {},
   "source": [
    "## Creating BDA project\n",
    "To start a BDA job, you need a BDA project, which organizes both standard and custom output configurations. This project is reusable, allowing you to apply the same configuration to process multiple video/audio files that share the same settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea323d3-6b32-4907-90c6-98acc11ad579",
   "metadata": {},
   "outputs": [],
   "source": [
    "bda_client = boto3.client('bedrock-data-automation', region_name=region)\n",
    "bda_runtime_client = boto3.client('bedrock-data-automation-runtime', region_name=region)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "kb_bucket_name = f'peak-load-kb-datasource-{agent_suffix}'\n",
    "\n",
    "s3_client.create_bucket(\n",
    "    Bucket=kb_bucket_name,\n",
    "    CreateBucketConfiguration={'LocationConstraint': region}\n",
    ")\n",
    "\n",
    "bucket_name_input = f's3://{bucket_name}/bda/input'      # DBA input path\n",
    "bucket_name_output = f's3://{bucket_name}/bda/output'    # DBA output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5511b89-4fb0-427e-b9c2-c1c2e9454da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name= f'bda-kb-project-{str(uuid.uuid4())[0:4]}'\n",
    "\n",
    "# delete project if it already exists\n",
    "projects_existing = [project for project in bda_client.list_data_automation_projects()[\"projects\"] if project[\"projectName\"] == project_name]\n",
    "if len(projects_existing) >0:\n",
    "    print(f\"Deleting existing project: {projects_existing[0]}\")\n",
    "    bda_client.delete_data_automation_project(projectArn=projects_existing[0][\"projectArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597724ce-d876-44df-864b-c70a05570bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_client.create_data_automation_project(\n",
    "    projectName=project_name,\n",
    "    projectDescription='BDA video processing project',\n",
    "    projectStage='DEVELOPMENT',\n",
    "    standardOutputConfiguration={\n",
    "        \"video\": {\n",
    "            \"extraction\": {\n",
    "                \"category\": {\n",
    "                    \"state\": \"ENABLED\",\n",
    "                    \"types\": [\"CONTENT_MODERATION\", \"TEXT_DETECTION\", \"TRANSCRIPT\"]\n",
    "                },\n",
    "                \"boundingBox\": {\"state\": \"ENABLED\"}\n",
    "            },\n",
    "            \"generativeField\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"VIDEO_SUMMARY\", \"CHAPTER_SUMMARY\", \"IAB\"]\n",
    "            }\n",
    "        },\n",
    "        \"audio\": {\n",
    "            \"extraction\": {\n",
    "                \"category\": {\n",
    "                    \"state\": \"ENABLED\", \n",
    "                    \"types\": [\"AUDIO_CONTENT_MODERATION\", \"TOPIC_CONTENT_MODERATION\", \"TRANSCRIPT\"]\n",
    "                }\n",
    "            },\n",
    "            \"generativeField\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"AUDIO_SUMMARY\", \"TOPIC_SUMMARY\", \"IAB\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102715c-032e-4e93-be3c-2aec1e574d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_project_arn = response.get(\"projectArn\")\n",
    "print(\"BDA kb project ARN:\", kb_project_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3b740-4727-477b-bd97-f3d136af2ea5",
   "metadata": {},
   "source": [
    "### Start BDA tasks\n",
    "We will now invoke the BDA API to process the uploaded audio file. You need to provide the BDA project ARN that we created at the beginning of the lab and specify an S3 location where BDA will store the output results.\n",
    "\n",
    "For a complete API reference for invoke a BDA async task, refer to this [document](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-data-automation-runtime/client/invoke_data_automation_async.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5274f66-193f-4e57-be29-64473aaa5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload video files\n",
    "import os\n",
    "from IPython.display import JSON, IFrame, Video, display, clear_output\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "path=\"./video\"\n",
    "        \n",
    "for root,dirs,files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_to_upload = os.path.join(root,file)\n",
    "                       \n",
    "        file_input = f'bda/input/video/{file}'\n",
    "        \n",
    "        print(f\"uploading file {file_to_upload} to {bucket_name}\")\n",
    "        s3_client.upload_file(file_to_upload,bucket_name,file_input)\n",
    "\n",
    "        output_name = f'bda/output/'\n",
    "        # Start BDA task video\n",
    "        response_vid = bda_runtime_client.invoke_data_automation_async(\n",
    "            inputConfiguration={'s3Uri':  f\"s3://{bucket_name}/{file_input}\"},\n",
    "            outputConfiguration={'s3Uri': f\"s3://{bucket_name}/{output_name}\"},\n",
    "            dataAutomationProfileArn= f'arn:aws:bedrock:us-west-2:{account_id}:data-automation-profile/us.data-automation-v1',\n",
    "            dataAutomationConfiguration={\n",
    "                'dataAutomationProjectArn':kb_project_arn,\n",
    "                #'dataAutomationArn': kb_project_arn,\n",
    "                'stage': 'DEVELOPMENT'\n",
    "            })\n",
    "\n",
    "        invocation_video_arn = response_vid.get(\"invocationArn\")\n",
    "        print(\"BDA video task started:\", invocation_video_arn)\n",
    "\n",
    "        statusVideo, status_vid_response = None, None\n",
    "        \n",
    "        while statusVideo not in [\"Success\",\"ServiceError\",\"ClientError\"]:\n",
    "            status_vid_response = bda_runtime_client.get_data_automation_status(\n",
    "                invocationArn=invocation_video_arn\n",
    "            )\n",
    "            statusVideo = status_vid_response.get(\"status\")\n",
    "    \n",
    "            clear_output(wait=True)\n",
    "            print(f\"{datetime.now().strftime('%H:%M:%S')} : \"\\\n",
    "              f\"BDA kb video task: {statusVideo} \")\n",
    "            time.sleep(5)\n",
    "\n",
    "\n",
    "        output_vid_config = status_vid_response.get(\"outputConfiguration\",{}).get(\"s3Uri\")\n",
    "        print(\"Ouput configuration file:\", output_vid_config)\n",
    "\n",
    "        # prep BDA output for the kb\n",
    "        out_vid_loc = status_vid_response['outputConfiguration']['s3Uri'].split(\"/job_metadata.json\", 1)[0].split(bucket_name+\"/\")[1]\n",
    "        out_vid_loc += \"/0/standard_output/0/result.json\"\n",
    "        print(out_vid_loc)\n",
    "        s3_client.download_file(bucket_name, out_vid_loc, f'result_vid_{file}.json')\n",
    "        \n",
    "        kb_file = f'data/result_vid_{file}_kb.json'\n",
    "        local_file =f'result_vid_{file}.json'\n",
    "        \n",
    "        #filter_json(f'result_vid_{file}.json', local_file)\n",
    "\n",
    "        print(f\"uploading file {local_file} to KB bucket {kb_bucket_name}\")\n",
    "        s3_client.upload_file(local_file, kb_bucket_name, kb_file )\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1954622-24d6-4c99-ad32-a8a12d572e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path to the parent directory\n",
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add both current and parent directories to sys.path\n",
    "sys.path.insert(0, current_dir)\n",
    "sys.path.insert(1, parent_dir)\n",
    "\n",
    "from utils.knowledge_base import BedrockKnowledgeBase\n",
    "\n",
    "knowledge_base_name = 'peak-load-kb-video'\n",
    "knowledge_base_description = \"Knowledge Base containing peak load video data that show various energy consumption patterns inside a house\"\n",
    "\n",
    "data=[{\"type\": \"S3\", \"bucket_name\": kb_bucket_name}]\n",
    "# For multi-modal RAG While instantiating BedrockKnowledgeBase, pass multi_modal= True and choose the parser you want to use\n",
    "\n",
    "knowledge_base = BedrockKnowledgeBase(\n",
    "    kb_name= knowledge_base_name,\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_sources=data,\n",
    "    multi_modal= True,\n",
    "    parser= 'BEDROCK_DATA_AUTOMATION', #'BEDROCK_FOUNDATION_MODEL'\n",
    "    chunking_strategy = \"FIXED_SIZE\", \n",
    "    suffix = f'{agent_suffix}-f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fcb97-53e3-4e21-95a9-ee32ee8ff00d",
   "metadata": {},
   "source": [
    "### Start the knowledge Bases ingestion job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c28076-d3b0-4850-a4ac-33d28f87e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the kb is available\n",
    "time.sleep(30)\n",
    "\n",
    "# sync knowledge base\n",
    "knowledge_base.start_ingestion_job()\n",
    "\n",
    "time.sleep(30)\n",
    "# keep the kb_id for invocation later in the invoke request\n",
    "kb_id = knowledge_base.get_knowledge_base_id()\n",
    "%store kb_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e3f55-845b-4bc7-8fbd-d63dc0dd46a6",
   "metadata": {},
   "source": [
    "### Associating Knowledge Base to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d47b7a-eef4-4f15-a437-108d9f6c4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate knowledge base\n",
    "kb_response = agents.associate_kb_with_agent(\n",
    "    agent_id=peak_agent[0],\n",
    "    description=\"This knowledge base contains relevant information for the agent to find energy waste pattern inside a household\",\n",
    "    kb_id=kb_id\n",
    ")\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dfcc57-5958-45e8-a4ea-53620142c017",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating Action Group\n",
    "\n",
    "On this session, we're going create an action group to handle the peak menagement and associate it with our agent. To do so, we will first create a Lambda function code to fulfill the execution of the agent's actions Next we will define the actions available actions that an agent can take using function details. Similar to the previous agent, you can also define the actions available using OpenAPI Schema.\n",
    "\n",
    "#### Creating Lambda function\n",
    "First let's create the lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfc71d-4b0e-4b00-9159-cc3efd2becbc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile peak_load.py\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import random\n",
    "\n",
    "from boto3.dynamodb.conditions import Key, Attr\n",
    "\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "dynamodb_table = os.getenv('dynamodb_table')\n",
    "dynamodb_pk = os.getenv('dynamodb_pk')\n",
    "dynamodb_sk = os.getenv('dynamodb_sk')\n",
    "\n",
    "def get_named_parameter(event, name):\n",
    "    return next(item for item in event['parameters'] if item['name'] == name)['value']\n",
    "    \n",
    "def populate_function_response(event, response_body):\n",
    "    return {'response': {'actionGroup': event['actionGroup'], 'function': event['function'],\n",
    "                'functionResponse': {'responseBody': {'TEXT': {'body': str(response_body)}}}}}\n",
    "\n",
    "def put_dynamodb(table_name, item):\n",
    "    table = dynamodb_resource.Table(table_name)\n",
    "    \n",
    "    resp = table.update_item(\n",
    "        Key={'customer_id': item['customer_id'],\n",
    "             'item_id': item['item_id']},\n",
    "        UpdateExpression='SET #attr1 = :val1',\n",
    "        ExpressionAttributeNames={'#attr1': 'quota'},\n",
    "        ExpressionAttributeValues={':val1':  item['quota']}\n",
    "    )\n",
    "    return resp\n",
    "\n",
    "def read_dynamodb(\n",
    "    table_name: str, \n",
    "    pk_field: str,\n",
    "    pk_value: str,\n",
    "    sk_field: str=None, \n",
    "    sk_value: str=None,\n",
    "    attr_key: str=None,\n",
    "    attr_val: str=None\n",
    "):\n",
    "    try:\n",
    "\n",
    "        table = dynamodb_resource.Table(table_name)\n",
    "        # Create expression\n",
    "        if sk_field:\n",
    "            key_expression = Key(pk_field).eq(pk_value) & Key(sk_field).eq(sk_value)\n",
    "        else:\n",
    "            key_expression = Key(pk_field).eq(pk_value)\n",
    "\n",
    "        if attr_key:\n",
    "            attr_expression = Attr(attr_key).eq(attr_val)\n",
    "            query_data = table.query(\n",
    "                KeyConditionExpression=key_expression,\n",
    "                FilterExpression=attr_expression\n",
    "            )\n",
    "        else:\n",
    "            query_data = table.query(\n",
    "                KeyConditionExpression=key_expression\n",
    "            )\n",
    "        \n",
    "        return query_data['Items']\n",
    "    except Exception:\n",
    "        print(f'Error querying table: {table_name}.')\n",
    "\n",
    "\n",
    "def detect_peak(customer_id):\n",
    "    return read_dynamodb(dynamodb_table, \n",
    "                         dynamodb_pk, \n",
    "                         customer_id, \n",
    "                         attr_key=\"peak\", attr_val=\"True\")\n",
    "\n",
    "def detect_non_essential_processes(customer_id):\n",
    "    return read_dynamodb(dynamodb_table, \n",
    "                         dynamodb_pk, \n",
    "                         customer_id,\n",
    "                         attr_key=\"essential\", attr_val=\"False\")\n",
    "\n",
    "                \n",
    "def redistribute_allocation(customer_id, item_id, quota):\n",
    "    item = {\n",
    "        'customer_id': customer_id,\n",
    "        'item_id': item_id,\n",
    "        'quota': quota\n",
    "    }\n",
    "    resp = put_dynamodb(dynamodb_table, item)\n",
    "    return \"Item {} has been updated. New quota: {}\".format(item_id, quota)\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(event)\n",
    "    \n",
    "    # name of the function that should be invoked\n",
    "    function = event.get('function', '')\n",
    "\n",
    "    # parameters to invoke function with\n",
    "    parameters = event.get('parameters', [])\n",
    "    \n",
    "    customer_id = get_named_parameter(event, \"customer_id\")\n",
    "\n",
    "    if function == 'detect_peak':    \n",
    "        result = detect_peak(customer_id)\n",
    "    elif function == 'detect_non_essential_processes':    \n",
    "        result = detect_non_essential_processes(customer_id)\n",
    "    elif function == 'redistribute_allocation':    \n",
    "        item_id = get_named_parameter(event, \"item_id\")\n",
    "        quota = get_named_parameter(event, \"quota\")\n",
    "        result = redistribute_allocation(customer_id, item_id, quota)\n",
    "    else:\n",
    "        result = f\"Error, function '{function}' not recognized\"\n",
    "\n",
    "    response = populate_function_response(event, result)\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566ff86c-e2c8-475a-833e-e0bc359c5767",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining available actions\n",
    "Now it's time to define the actions that can be taken by the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438266d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "functions_def = [\n",
    "    {\n",
    "        \"name\": \"detect_peak\",\n",
    "        \"description\": \"\"\"detect consumption peak during current month\"\"\",\n",
    "        \"parameters\": {\n",
    "                        \"customer_id\": {\n",
    "                            \"description\": \"The ID of the customer\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"detect_non_essential_processes\",\n",
    "        \"description\": \"\"\"detect non-essential processes that are causing the peaks\"\"\",\n",
    "        \"parameters\": {\n",
    "                        \"customer_id\": {\n",
    "                            \"description\": \"The ID of the customer\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"redistribute_allocation\",\n",
    "        \"description\": \"\"\"reduce/increase allocated quota for a specific \n",
    "                            item during current month\"\"\",\n",
    "        \"parameters\": {\n",
    "                        \"customer_id\": {\n",
    "                            \"description\": \"The ID of the customer\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"item_id\": {\n",
    "                            \"description\": \"Item that will be updated\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"quota\": {\n",
    "                            \"description\": \"new quota\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a81c4d-1bf6-4df3-a0b5-0add070d2b73",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Associating action group to agent\n",
    "Finally, we can associate a new action group with our previously created agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c21c0-7a28-417c-a506-021a57b73596",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resp = agents.add_action_group_with_lambda(\n",
    "    agent_name=peak_agent_name,\n",
    "    lambda_function_name=peak_lambda_name,\n",
    "    source_code_file=\"peak_load.py\",\n",
    "    agent_functions=functions_def,\n",
    "    agent_action_group_name=\"peak_load_actions\",\n",
    "    agent_action_group_description=\"Function to get usage, peaks, redistribution for a user\",\n",
    "    dynamo_args=dynamoDB_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469df2c4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading data to DynamoDB\n",
    "\n",
    "Now that we've created our agent, let's load some generated data to DynamoDB. That will allow the agent to interact with some live data to perform actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2ad79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"3_peak_sample_data.json\") as f:\n",
    "    table_items = [json.loads(line) for line in f]\n",
    "\n",
    "agents.load_dynamodb(dynamodb_table, table_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3cf13f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Testing that data was loaded on DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e5227",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resp = agents.query_dynamodb(dynamodb_table, dynamodb_pk, '1', dynamodb_sk, \"1\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc0aff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing Agent\n",
    "\n",
    "Now, let's run some tests on the agent we just created to make sure it's working. To do so we will use our test alias: `TSTALIASID` which allows you to invoke a draft version of your agent\n",
    "\n",
    "### Testing non-essential process detection\n",
    "First let's ask a question related to non-essential process detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69a4c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = agents.invoke(\n",
    "    \"What's causing my peak load? My id is 2\", \n",
    "    peak_agent[0], enable_trace=True\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d80cb0-f63d-418b-b5b0-9cf10f759ffd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing load optimization\n",
    "Next let's ask the agent to optimize the consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a1fb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = agents.invoke(\n",
    "    \"Is it possible to optimize my consumption? My id is 1\", \n",
    "    peak_agent[0], enable_trace=True\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71291bf0-90fc-471f-975e-5ad1f64af28c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing load relocation\n",
    "Finally, let's ask the agent to do some quota relloacation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c7ba4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = agents.invoke(\n",
    "    \"\"\"Is it possible to change quota allocation? My id is 2, my item is 5 and new quota is 100\"\"\", \n",
    "    peak_agent[0], enable_trace=True\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6a8d36-cb73-4e95-b345-dbaf4631f42e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create alias\n",
    "\n",
    "As you can see, you can use your agent with the `TSTALIASID` to complete tasks. \n",
    "However, for multi-agents collaboration it is expected that you first test your agent and only use it once it is fully functional. \n",
    "Therefore to use an agent as a sub-agent in a multi-agent collaboration you first need to create an agent alias and connect it to a new version. \n",
    "\n",
    "Since we've tested and validated our agent, let's now create an alias for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0d1ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peak_agent_alias_id, peak_agent_alias_arn = agents.create_agent_alias(\n",
    "    peak_agent[0], 'v1'\n",
    ")\n",
    "peak_agent_id = peak_agent[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29db93eb-9a51-48d2-a6ae-a31b7b5ddde1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Store environment variables to be used on next notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d40844-c72b-4114-8415-8cefbe65ebb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peak_agent_arn = agents.get_agent_arn_by_name(peak_agent_name)\n",
    "peak_dynamodb = dynamodb_table\n",
    "\n",
    "%store peak_agent_arn\n",
    "%store peak_agent_alias_arn\n",
    "%store peak_agent_alias_id\n",
    "%store peak_lambda_name\n",
    "%store peak_agent_name\n",
    "%store peak_agent_id\n",
    "%store peak_dynamodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99986c91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peak_agent_arn, peak_agent_alias_arn, peak_agent_alias_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c887c74f-0e08-43bb-9b68-32d758283fb0",
   "metadata": {},
   "source": [
    "## Testing Agent with KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a51b58-3af7-4f6e-aeb9-23f53209a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = agents.invoke(\n",
    "    #\"give me a list of videos related with lamps\", \n",
    "    \"what energy efficiency advice can you give based on the videos showing lamps in the living room, please include the original knowledge base source\",\n",
    "    #\"what energy efficiency advice can you give based on the videos related fridge\",\n",
    "    peak_agent[0], \n",
    "    #enable_trace=True,\n",
    "    #end_session=True,\n",
    "    agent_alias_id=peak_agent_alias_id\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0c0e9-a431-4b13-8345-30a446f0727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = agents.invoke(\n",
    "    #\"give me a list of videos related with lamps\", \n",
    "    \"Examine appliances shown in these videos, please provide energy saving advice based on the usage pattern of my refrigerator, please include the original knowledge base source\",\n",
    "    #\"what energy efficiency advice can you give based on the videos related fridge\",\n",
    "    peak_agent[0], \n",
    "    #enable_trace=True,\n",
    "    #end_session=True,\n",
    "    agent_alias_id=peak_agent_alias_id\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375b4a4-4604-4225-90ed-5aaab412ef54",
   "metadata": {},
   "source": [
    "### Load the energy consumption video clip referred by the agent in citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9beeb-19e9-44e2-8079-dc24bf1b922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract video path and timestamps from the response\n",
    "import re\n",
    "from IPython.display import HTML\n",
    "from utils.knowledge_base_operators import play_video_from_bedrock_response\n",
    "\n",
    "play_video_from_bedrock_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e3426-7858-427d-adf3-d73081d08b12",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Next Steps\n",
    "Congratulations! We've now created all of our sub-agents. Next we will create our supervisor agent to do the orchestration between the sub-agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
